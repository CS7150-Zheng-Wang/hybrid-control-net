{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58cf31-091c-462c-a2fa-320a49212f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from utils.load_util import load_sdxl_models, load_pipe\n",
    "\n",
    "\n",
    "\n",
    "distillation_type='dmd' # what type of distillation model do you want to use (\"dmd\", \"lcm\", \"turbo\", \"lightning\")\n",
    "device = 'cuda:0'\n",
    "weights_dtype = torch.bfloat16\n",
    "\n",
    "pipe, base_unet, base_scheduler, distilled_unet, distilled_scheduler = load_sdxl_models(distillation_type=distillation_type, \n",
    "                                                                                        weights_dtype=weights_dtype, \n",
    "                                                                                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b0b8e-5e96-4c91-b427-83a2c2564215",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_guidance_scale= 0\n",
    "distilled_guidance_scale = 0\n",
    "\n",
    "run_base_till_timestep = None # set to none if you want it to be automatically decided\n",
    "run_distilled_from_timestep = 1\n",
    "\n",
    "\n",
    "# how many total timesteps to set for schedulers\n",
    "base_num_inference_steps = 4 \n",
    "distilled_num_inference_steps = 4\n",
    "\n",
    "# for paper consistent results use this\n",
    "base_scheduler = distilled_scheduler\n",
    "\n",
    "# set the timesteps for the model\n",
    "base_scheduler.set_timesteps(base_num_inference_steps)\n",
    "distilled_scheduler.set_timesteps(distilled_num_inference_steps)\n",
    "\n",
    "# automatically figure out what is the natural point to turn off the base model\n",
    "if run_base_till_timestep is None:\n",
    "    # check the timestep from which you need to run the model\n",
    "    distilled_timestep = distilled_scheduler.timesteps[run_distilled_from_timestep]\n",
    "\n",
    "    # check the closest timestep in basemodel\n",
    "    base_timesteps = abs(base_scheduler.timesteps - distilled_timestep)\n",
    "    run_base_till_timestep = base_timesteps.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488954db-b261-48b4-8bf1-47b70acb5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_images = 1\n",
    "prompt = 'image of a dog'\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "total_time = 0\n",
    "all_images = []\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "# Generate images\n",
    "for i in tqdm(range(num_images)):\n",
    "    # Generate random seed\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    generator = torch.manual_seed(seed)\n",
    "    \n",
    "    # First use base model\n",
    "    pipe.unet = base_unet\n",
    "    pipe.scheduler = base_scheduler\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    base_latents = pipe(prompt=prompt, from_timestep=0, till_timestep=run_base_till_timestep, \n",
    "                         guidance_scale=base_guidance_scale, num_inference_steps=base_num_inference_steps, \n",
    "                         output_type='latent')\n",
    "    \n",
    "    # Switch to distilled model\n",
    "    pipe.unet = distilled_unet\n",
    "    pipe.scheduler = distilled_scheduler\n",
    "    \n",
    "    \n",
    "    pil_image = pipe(prompt=prompt, start_latents=base_latents, guidance_scale=distilled_guidance_scale,\n",
    "                      from_timestep=run_distilled_from_timestep, till_timestep=None, \n",
    "                      num_inference_steps=distilled_num_inference_steps)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    runtime = end_time - start_time\n",
    "    total_time += runtime\n",
    "    \n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfaa65-8d86-471d-8591-ad7924bde1c2",
   "metadata": {},
   "source": [
    "# Individual Pipe Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784e391-7966-4234-8d97-08e0ee3e3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from utils.load_util import load_sdxl_models, load_pipe\n",
    "\n",
    "\n",
    "\n",
    "distillation_type= None # set to None for base model\n",
    "device = 'cuda:0'\n",
    "weights_dtype = torch.bfloat16\n",
    "\n",
    "pipe = load_pipe(distillation_type=distillation_type, \n",
    "                  weights_dtype=weights_dtype, \n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545d82e-58a1-42c9-9bf6-51d4266fd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_scale = 8\n",
    "num_inference_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231963e1-b451-456e-b42a-5040d43c12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_images = 1  # 5x5 grid\n",
    "prompt = 'image of a wizard'\n",
    "\n",
    "# Initialize variables\n",
    "total_time = 0\n",
    "all_images = []\n",
    "\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "    \n",
    "# Generate images\n",
    "for i in tqdm(range(num_images)):\n",
    "    # Generate random seed\n",
    "    seed = np.random.randint(0, 2**32 - 1)\n",
    "    generator = torch.manual_seed(seed)\n",
    "    \n",
    "    # First use base model    \n",
    "    start_time = time.perf_counter()\n",
    "    pil_image = pipe(prompt=prompt, guidance_scale=guidance_scale,\n",
    "                      num_inference_steps=num_inference_steps)[0]\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    runtime = end_time - start_time\n",
    "    total_time += runtime\n",
    "    \n",
    "    # Convert PIL image to numpy array and append to list\n",
    "    display(pil_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
